{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  tensorflow as tf\n",
    "import  numpy as np\n",
    "from    tensorflow import keras\n",
    "import  os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "\n",
    "        # here must specify shape instead of tensor !\n",
    "        # name here is meanless !\n",
    "        # [dim_in, dim_out]\n",
    "        self.w = self.add_variable('meanless-name', [13, 1])\n",
    "        # [dim_out]\n",
    "        self.b = self.add_variable('meanless-name', [1])\n",
    "\n",
    "        print(self.w.shape, self.b.shape)\n",
    "        print(type(self.w), tf.is_tensor(self.w), self.w.name)\n",
    "        print(type(self.b), tf.is_tensor(self.b), self.b.name)\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        x = tf.matmul(x, self.w) + self.b\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test Linear Regression on boston housing prediction\n",
    "def main():\n",
    "    \n",
    "    tf.random.set_seed(22)\n",
    "    np.random.seed(22)\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "    assert tf.__version__.startswith('2.')\n",
    "\n",
    "    (x_train, y_train), (x_val, y_val) = keras.datasets.boston_housing.load_data()\n",
    "    \n",
    "    x_train, x_val = x_train.astype(np.float32), x_val.astype(np.float32)\n",
    "    # (404, 13) (404,) (102, 13) (102,)\n",
    "    print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n",
    "    # mis-leading issues:\n",
    "    # 1. (x_train, y_train) cannot be written as [x_train, y_train]\n",
    "    db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(64)\n",
    "    db_val = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(102)\n",
    "\n",
    "    model = Regressor()\n",
    "    criteon = keras.losses.MeanSquaredError()\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
    "\n",
    "    for epoch in range(200):\n",
    "\n",
    "        for step, (x, y) in enumerate(db_train):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # [b, 1]\n",
    "                logits = model(x)\n",
    "                # [b]\n",
    "                logits = tf.squeeze(logits, axis=1)\n",
    "                # [b] vs [b]\n",
    "                loss = criteon(y, logits)\n",
    "\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        print(epoch, 'loss:', loss.numpy())\n",
    "\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "\n",
    "            for x, y in db_val:\n",
    "                # [b, 1]\n",
    "                logits = model(x)\n",
    "                # [b]\n",
    "                logits = tf.squeeze(logits, axis=1)\n",
    "                # [b] vs [b]\n",
    "                loss = criteon(y, logits)\n",
    "\n",
    "                print(epoch, 'val loss:', loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1009 14:13:33.442121 4624827840 deprecation.py:323] From <ipython-input-2-59a106cfbed4>:9: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (404,) (102, 13) (102,)\n",
      "(13, 1) (1,)\n",
      "<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'> True meanless-name:0\n",
      "<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'> True meanless-name:0\n",
      "0 loss: 39695.023\n",
      "0 val loss: 36500.55\n",
      "1 loss: 18709.295\n",
      "2 loss: 6534.532\n",
      "3 loss: 1271.5453\n",
      "4 loss: 51.911457\n",
      "5 loss: 236.73438\n",
      "6 loss: 401.17065\n",
      "7 loss: 293.0813\n",
      "8 loss: 127.25572\n",
      "9 loss: 48.90026\n",
      "10 loss: 42.267822\n",
      "10 val loss: 124.677475\n",
      "11 loss: 49.233364\n",
      "12 loss: 47.35646\n",
      "13 loss: 42.244392\n",
      "14 loss: 39.96756\n",
      "15 loss: 39.822285\n",
      "16 loss: 39.75222\n",
      "17 loss: 39.398033\n",
      "18 loss: 39.11085\n",
      "19 loss: 38.935925\n",
      "20 loss: 38.738976\n",
      "20 val loss: 120.31867\n",
      "21 loss: 38.4842\n",
      "22 loss: 38.209473\n",
      "23 loss: 37.937233\n",
      "24 loss: 37.66733\n",
      "25 loss: 37.395893\n",
      "26 loss: 37.11916\n",
      "27 loss: 36.833473\n",
      "28 loss: 36.537872\n",
      "29 loss: 36.234394\n",
      "30 loss: 35.925827\n",
      "30 val loss: 114.44217\n",
      "31 loss: 35.613995\n",
      "32 loss: 35.29952\n",
      "33 loss: 34.98245\n",
      "34 loss: 34.662853\n",
      "35 loss: 34.341164\n",
      "36 loss: 34.01807\n",
      "37 loss: 33.69431\n",
      "38 loss: 33.370483\n",
      "39 loss: 33.04701\n",
      "40 loss: 32.72425\n",
      "40 val loss: 107.796265\n",
      "41 loss: 32.402515\n",
      "42 loss: 32.082172\n",
      "43 loss: 31.763544\n",
      "44 loss: 31.44696\n",
      "45 loss: 31.132694\n",
      "46 loss: 30.82099\n",
      "47 loss: 30.512049\n",
      "48 loss: 30.20609\n",
      "49 loss: 29.903301\n",
      "50 loss: 29.603855\n",
      "50 val loss: 101.227325\n",
      "51 loss: 29.307882\n",
      "52 loss: 29.015554\n",
      "53 loss: 28.726984\n",
      "54 loss: 28.442276\n",
      "55 loss: 28.161564\n",
      "56 loss: 27.884897\n",
      "57 loss: 27.612406\n",
      "58 loss: 27.344128\n",
      "59 loss: 27.080154\n",
      "60 loss: 26.820526\n",
      "60 val loss: 95.07066\n",
      "61 loss: 26.565311\n",
      "62 loss: 26.31454\n",
      "63 loss: 26.068253\n",
      "64 loss: 25.826488\n",
      "65 loss: 25.589273\n",
      "66 loss: 25.356623\n",
      "67 loss: 25.128546\n",
      "68 loss: 24.905064\n",
      "69 loss: 24.68617\n",
      "70 loss: 24.471893\n",
      "70 val loss: 89.4915\n",
      "71 loss: 24.262197\n",
      "72 loss: 24.057081\n",
      "73 loss: 23.856548\n",
      "74 loss: 23.660564\n",
      "75 loss: 23.469118\n",
      "76 loss: 23.2822\n",
      "77 loss: 23.099771\n",
      "78 loss: 22.921797\n",
      "79 loss: 22.748264\n",
      "80 loss: 22.579117\n",
      "80 val loss: 84.54929\n",
      "81 loss: 22.414341\n",
      "82 loss: 22.253872\n",
      "83 loss: 22.097692\n",
      "84 loss: 21.945744\n",
      "85 loss: 21.797977\n",
      "86 loss: 21.654358\n",
      "87 loss: 21.514828\n",
      "88 loss: 21.379349\n",
      "89 loss: 21.24785\n",
      "90 loss: 21.120287\n",
      "90 val loss: 80.23591\n",
      "91 loss: 20.996605\n",
      "92 loss: 20.876755\n",
      "93 loss: 20.760662\n",
      "94 loss: 20.648287\n",
      "95 loss: 20.53955\n",
      "96 loss: 20.434416\n",
      "97 loss: 20.332806\n",
      "98 loss: 20.23467\n",
      "99 loss: 20.139938\n",
      "100 loss: 20.048561\n",
      "100 val loss: 76.50185\n",
      "101 loss: 19.960466\n",
      "102 loss: 19.875599\n",
      "103 loss: 19.793884\n",
      "104 loss: 19.715279\n",
      "105 loss: 19.639706\n",
      "106 loss: 19.567114\n",
      "107 loss: 19.497435\n",
      "108 loss: 19.430607\n",
      "109 loss: 19.366571\n",
      "110 loss: 19.305264\n",
      "110 val loss: 73.276276\n",
      "111 loss: 19.246628\n",
      "112 loss: 19.190596\n",
      "113 loss: 19.137115\n",
      "114 loss: 19.086132\n",
      "115 loss: 19.03757\n",
      "116 loss: 18.991383\n",
      "117 loss: 18.94751\n",
      "118 loss: 18.905901\n",
      "119 loss: 18.866491\n",
      "120 loss: 18.829227\n",
      "120 val loss: 70.4817\n",
      "121 loss: 18.794056\n",
      "122 loss: 18.760914\n",
      "123 loss: 18.729765\n",
      "124 loss: 18.700542\n",
      "125 loss: 18.673191\n",
      "126 loss: 18.647678\n",
      "127 loss: 18.623938\n",
      "128 loss: 18.601929\n",
      "129 loss: 18.581593\n",
      "130 loss: 18.562897\n",
      "130 val loss: 68.043526\n",
      "131 loss: 18.54578\n",
      "132 loss: 18.530209\n",
      "133 loss: 18.516125\n",
      "134 loss: 18.50349\n",
      "135 loss: 18.49227\n",
      "136 loss: 18.482409\n",
      "137 loss: 18.473873\n",
      "138 loss: 18.466618\n",
      "139 loss: 18.460604\n",
      "140 loss: 18.455793\n",
      "140 val loss: 65.89565\n",
      "141 loss: 18.452147\n",
      "142 loss: 18.449635\n",
      "143 loss: 18.448212\n",
      "144 loss: 18.447845\n",
      "145 loss: 18.448496\n",
      "146 loss: 18.45014\n",
      "147 loss: 18.452736\n",
      "148 loss: 18.456264\n",
      "149 loss: 18.460682\n",
      "150 loss: 18.465954\n",
      "150 val loss: 63.982643\n",
      "151 loss: 18.472065\n",
      "152 loss: 18.478973\n",
      "153 loss: 18.48666\n",
      "154 loss: 18.49509\n",
      "155 loss: 18.50424\n",
      "156 loss: 18.514093\n",
      "157 loss: 18.524609\n",
      "158 loss: 18.535769\n",
      "159 loss: 18.547554\n",
      "160 loss: 18.559937\n",
      "160 val loss: 62.260128\n",
      "161 loss: 18.572893\n",
      "162 loss: 18.5864\n",
      "163 loss: 18.600443\n",
      "164 loss: 18.614994\n",
      "165 loss: 18.63004\n",
      "166 loss: 18.645554\n",
      "167 loss: 18.661522\n",
      "168 loss: 18.67793\n",
      "169 loss: 18.694752\n",
      "170 loss: 18.711975\n",
      "170 val loss: 60.693565\n",
      "171 loss: 18.729574\n",
      "172 loss: 18.747547\n",
      "173 loss: 18.765871\n",
      "174 loss: 18.784529\n",
      "175 loss: 18.803503\n",
      "176 loss: 18.822794\n",
      "177 loss: 18.842365\n",
      "178 loss: 18.862223\n",
      "179 loss: 18.882343\n",
      "180 loss: 18.902721\n",
      "180 val loss: 59.25666\n",
      "181 loss: 18.923334\n",
      "182 loss: 18.944183\n",
      "183 loss: 18.965244\n",
      "184 loss: 18.986517\n",
      "185 loss: 19.007978\n",
      "186 loss: 19.029623\n",
      "187 loss: 19.051445\n",
      "188 loss: 19.073435\n",
      "189 loss: 19.095577\n",
      "190 loss: 19.117867\n",
      "190 val loss: 57.92948\n",
      "191 loss: 19.140293\n",
      "192 loss: 19.162846\n",
      "193 loss: 19.18552\n",
      "194 loss: 19.208302\n",
      "195 loss: 19.231186\n",
      "196 loss: 19.254162\n",
      "197 loss: 19.27723\n",
      "198 loss: 19.300373\n",
      "199 loss: 19.323595\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
