{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "import  os\n",
    "import  tensorflow as tf\n",
    "import  numpy as np\n",
    "from    tensorflow import keras\n",
    "from    PIL import Image\n",
    "from    matplotlib import pyplot as plt\n",
    "\n",
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train.astype(np.float32) / 255., x_test.astype(np.float32) / 255.\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "# image grid\n",
    "new_im = Image.new('L', (280, 280))\n",
    "\n",
    "image_size = 28*28\n",
    "h_dim = 20\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AE, self).__init__()\n",
    "        # 784 => 512\n",
    "        self.fc1 = keras.layers.Dense(512)\n",
    "        # 512 => h\n",
    "        self.fc2 = keras.layers.Dense(h_dim)    # bottleneck \n",
    "        # h => 512\n",
    "        self.fc3 = keras.layers.Dense(512)\n",
    "        # 512 => image\n",
    "        self.fc4 = keras.layers.Dense(image_size)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = tf.nn.relu(self.fc1(x))\n",
    "        x = (self.fc2(x))\n",
    "        return x\n",
    "\n",
    "    def decode_logits(self, h):\n",
    "        x = tf.nn.relu(self.fc3(h))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, h):\n",
    "        return tf.nn.sigmoid(self.decode_logits(h))\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        # encoder\n",
    "        h = self.encode(inputs)\n",
    "        # decode\n",
    "        x_reconstructed_logits = self.decode_logits(h)\n",
    "        return x_reconstructed_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ae_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              multiple                  401920    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  10260     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              multiple                  10752     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  402192    \n",
      "=================================================================\n",
      "Total params: 825,124\n",
      "Trainable params: 825,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = AE()\n",
    "model.build(input_shape=(4, image_size))\n",
    "model.summary()\n",
    "optimizer = keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1009 17:31:49.680379 4550337984 deprecation.py:323] From /anaconda3/lib/python3.6/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/5], Step [50/600], Reconst Loss: 160.8146\n",
      "Epoch[1/5], Step [100/600], Reconst Loss: 127.1601\n",
      "Epoch[1/5], Step [150/600], Reconst Loss: 109.0554\n",
      "Epoch[1/5], Step [200/600], Reconst Loss: 103.8838\n",
      "Epoch[1/5], Step [250/600], Reconst Loss: 85.9174\n",
      "Epoch[1/5], Step [300/600], Reconst Loss: 85.5601\n",
      "Epoch[1/5], Step [350/600], Reconst Loss: 89.2355\n",
      "Epoch[1/5], Step [400/600], Reconst Loss: 80.7757\n",
      "Epoch[1/5], Step [450/600], Reconst Loss: 81.8119\n",
      "Epoch[1/5], Step [500/600], Reconst Loss: 87.8791\n",
      "Epoch[1/5], Step [550/600], Reconst Loss: 79.7579\n",
      "Epoch[1/5], Step [600/600], Reconst Loss: 79.2986\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'images/vae_reconstructed_epoch_1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7526e67efece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mnew_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/vae_reconstructed_epoch_%d.png'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1989\u001b[0m                 \u001b[0;31m# Open also for reading (\"+\"), because TIFF save_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m                 \u001b[0;31m# writer needs to go back and edit the written data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images/vae_reconstructed_epoch_1.png'"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(x_train) # here doesn't need labels\n",
    "dataset = dataset.shuffle(batch_size * 5).batch(batch_size)\n",
    "\n",
    "num_batches = x_train.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for step, x in enumerate(dataset):\n",
    "\n",
    "        x = tf.reshape(x, [-1, image_size])\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Forward pass\n",
    "            x_reconstruction_logits = model(x)\n",
    "\n",
    "            # Compute reconstruction loss and kl divergence\n",
    "            # Scaled by `image_size` for each individual pixel.\n",
    "            reconstruction_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=x, logits=x_reconstruction_logits)\n",
    "            reconstruction_loss = tf.reduce_sum(reconstruction_loss) / batch_size\n",
    "\n",
    "        gradients = tape.gradient(reconstruction_loss, model.trainable_variables) \n",
    "        gradients,_ = tf.clip_by_global_norm(gradients, 15)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        if (step + 1) % 50 == 0:\n",
    "            print(\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}\"\n",
    "                  .format(epoch + 1, num_epochs, step + 1, num_batches, float(reconstruction_loss)))\n",
    "\n",
    "     # Save the reconstructed images of last batch\n",
    "    out_logits = model(x[:batch_size // 2])\n",
    "    out = tf.nn.sigmoid(out_logits)  # out is just the logits, use sigmoid\n",
    "    out = tf.reshape(out, [-1, 28, 28]).numpy() * 255\n",
    "\n",
    "    x = tf.reshape(x[:batch_size // 2], [-1, 28, 28])\n",
    "\n",
    "    x_concat = tf.concat([x, out], axis=0).numpy() * 255.\n",
    "    x_concat = x_concat.astype(np.uint8)\n",
    "\n",
    "    index = 0\n",
    "    for i in range(0, 280, 28):\n",
    "        for j in range(0, 280, 28):\n",
    "            im = x_concat[index]\n",
    "            im = Image.fromarray(im, mode='L')\n",
    "            new_im.paste(im, (i, j))\n",
    "            index += 1\n",
    "\n",
    "    new_im.save('images/vae_reconstructed_epoch_%d.png' % (epoch + 1))\n",
    "    plt.imshow(np.asarray(new_im))\n",
    "    plt.show()\n",
    "    print('New images saved !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
